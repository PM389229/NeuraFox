üß† Interpr√®te Multilingue Hors Ligne
Nous avons cr√©√© ce projet pour pouvoir traduire et synth√©tiser des conversations, m√™me sans connexion Internet.

üåü Ce que l'app peut faire
Transcription intelligente : L'app √©coute ce que tu dis et le convertit en texte.

Pour le fran√ßais et l'anglais, elle utilise Vosk.

Pour le japonais et le mandarin, on a opt√© pour Whisper d'OpenAI.

D√©tection de silence : Pas besoin d'appuyer sur un bouton pour arr√™ter l'enregistrement. L'app est faite pour s'arr√™ter seule apr√®s 2 secondes de silence.

Traduction hors ligne : Elle utilise le mod√®le SeamlessM4T de Meta pour traduire les phrases sans avoir besoin d'√™tre connect√©e √† Internet.

Synth√®se vocale (TTS) : Une fois le texte traduit, l'app le transforme en voix. On utilise des mod√®les diff√©rents pour un rendu naturel :

MMS-TTS pour le fran√ßais et l'anglais.

MeloTTS (via un script s√©par√©) pour le japonais (JA) et le mandarin (ZH), g√©rant ainsi les d√©pendances complexes.

üõ†Ô∏è L'installation : Les deux environnements virtuels
Pour que tout fonctionne comme sur des roulettes, il te faudra deux environnements virtuels. C'est la meilleure fa√ßon de g√©rer toutes les d√©pendances sans que tout ne s'emm√™le.

1. D'abord, on clone le projet
Ouvre le terminal et tape ces commandes pour r√©cup√©rer le code :

git clone [[https://github.com/PM389229/NeuraFox.git](https://github.com/PM389229/NeuraFox.git)]
cd votre-projet

2. Le premier environnement (principal)
On va l'appeler venv. Il contient la majorit√© des d√©pendances pour l'interface Streamlit et la reconnaissance vocale.

python -m venv venv
source venv/bin/activate  # Sur Mac/Linux
# venv\Scripts\activate  # Sur Windows
pip install -r requirements.txt

Note : N'oublie pas de v√©rifier que ton fichier requirements.txt est √† jour et contient toutes les librairies, comme streamlit, transformers, torch, whisper, etc.

3. Le second environnement (sp√©cial TTS Japonais et Mandarin)
Ce mod√®le de synth√®se vocale (MeloTTS) a des d√©pendances tr√®s sp√©cifiques (qui rentraient en conflit avec le premier environnement virtuel), d'o√π la n√©cessit√© d'un environnement s√©par√©. On l'appelle melotts_env.

python -m venv melotts_env
source melotts_env/bin/activate # Sur Mac/Linux
# melotts_env\Scripts\activate  # Sur Windows
pip install TTS[ja]

Note : Cet environnement est utilis√© par le script externe melo_tts_service.py pour g√©n√©rer la voix japonaise et mandarine. Il est appel√© via subprocess par le service principal.

4. T√©l√©charger les mod√®les
Vu que ces mod√®les sont tr√®s lourds, on ne les a pas mis dans le d√©p√¥t.
Il faudra les t√©l√©charger manuellement et les placer dans les bons dossiers. Voici les instructions pr√©cises pour chaque cas.

üéôÔ∏è Mod√®les de reconnaissance vocale (Vosk)
Ces mod√®les sont essentiels pour la transcription du fran√ßais et de l'anglais.

Va sur le site officiel de Vosk : https://alphacephei.com/vosk/models

Cherche les mod√®les "French small model" et "English small model".

T√©l√©charge les deux archives .zip correspondantes.

Une fois t√©l√©charg√©es, d√©compresse-les. Cr√©e deux nouveaux dossiers √† la racine de ton projet : vosk-model-fr et vosk-model-en. Place les fichiers extraits dans ces dossiers.

üéôÔ∏è Mod√®le de reconnaissance vocale japonais et mandarin (Whisper)
Rien √† faire ici ! Le mod√®le Whisper d'OpenAI est tr√®s pratique car il se t√©l√©charge automatiquement la premi√®re fois que tu lances un script qui l'utilise. La librairie est d√©j√† incluse dans ton requirements.txt donc l'installation se fait en m√™me temps que le reste des d√©pendances.

üåê Mod√®le de traduction (SeamlessM4T de Meta)
Ce mod√®le permet de traduire sans connexion Internet. Il est tr√®s volumineux, mais il est au c≈ìur du projet.

Rends-toi sur la page Hugging Face du mod√®le : https://huggingface.co/meta-llama/seamless-m4t-medium

Dans l'onglet "Files and versions", clique sur "Download all files" pour t√©l√©charger le dossier complet. C'est une archive .zip ou tu peux utiliser git lfs si tu es familier avec.

Une fois t√©l√©charg√©, renomme le dossier en hf-seamless-m4t-medium et place-le √† la racine de ton projet.

üó£Ô∏è Mod√®les de synth√®se vocale (TTS)
Ici, on a une petite particularit√©.

TTS pour l'anglais et le fran√ßais (MMS-TTS) :
Rien √† faire ici ! Le service principal g√®re le t√©l√©chargement des mod√®les MMS-TTS (pour FR et EN) directement via Hugging Face lors du premier lancement, et les met en cache.

TTS pour le japonais et le mandarin (MeloTTS) :
Rien √† faire ici non plus ! La librairie melo.api.TTS est con√ßue pour g√©rer le t√©l√©chargement et la mise en cache des mod√®les automatiquement. La premi√®re fois que tu ex√©cuteras un script utilisant un mod√®le pour ces langues dans l'environnement melotts_env, la librairie s'occupera du t√©l√©chargement.

üèÉ Comment lancer l'application
Une fois que tous les mod√®les sont en place, tu peux lancer l'interface utilisateur.

# Assure-toi d'√™tre dans ton premier environnement (venv)
source venv/bin/activate
streamlit run app.py

L'application va se lancer automatiquement dans ton navigateur.

‚òÅÔ∏è Pour la mettre en ligne (Kaggle ou Colab)
√áa sera la prochaine √©tape. Quand tu seras pr√™t, il faudra juste uploader tous les fichiers et installer les d√©pendances et les mod√®les directement sur la plateforme.

ü§ù Participer au projet
Si tu as des id√©es pour am√©liorer l'app, n'h√©site pas ! Les pull requests sont les bienvenues.