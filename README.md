






                    üß† Interpr√®te Multilingue Hors Ligne

On a cr√©√© ce projet pour pouvoir traduire et synth√©tiser des conversations, m√™me sans connexion Internet. 


                    üåü Ce que l'app peut faire


Transcription intelligente : L'app √©coute ce que tu dis et le convertit en texte. 

Pour le fran√ßais et l'anglais, elle utilise Vosk, et pour le japonais, on a opt√© pour Whisper d'OpenAI.

D√©tection de silence : Pas besoin d'appuyer sur un bouton pour arr√™ter l'enregistrement. L'app est faite pour s'arr√™ter seule apr√®s 2 secondes de silence.

Traduction hors ligne : Elle utilise le mod√®le SeamlessM4T de Meta pour traduire les phrases sans avoir besoin d'√™tre connect√©e √† Internet.


Synth√®se vocale (TTS) : Une fois le texte traduit, l'app le transforme en voix. On a utilis√© plusieurs scripts pour que √ßa sonne le plus naturel possible, peu importe la langue.





                 üõ†Ô∏è L'installation : Les deux environnements virtuels



Pour que tout fonctionne comme sur des roulettes, il te faudra deux environnements virtuels. C'est la meilleure fa√ßon de g√©rer toutes les d√©pendances sans que tout ne s'emm√™le.





1. D'abord, on clone le projet
Ouvre le terminal et tape ces commandes pour r√©cup√©rer le code :

git clone [https://github.com/PM389229/NeuraFox.git]
cd votre-projet






2. Le premier environnement (principal)
On va l'appeler venv. Il contient la majorit√© des d√©pendances pour l'interface Streamlit et la reconnaissance vocale.

python -m venv venv
source venv/bin/activate  # Sur Mac/Linux
# venv\Scripts\activate  # Sur Windows
pip install -r requirements.txt

Note : N'oublie pas de v√©rifier que ton fichier requirements.txt est √† jour et contient toutes les librairies, comme streamlit, transformers, torch, whisper, etc.





3. Le second environnement (sp√©cial TTS japonais)

Ce mod√®le de synth√®se vocale japonaise a des d√©pendances tr√®s sp√©cifiques (qui rentraient en conflit avec le premier environnement virtuel , il n√©cessite des versions pr√©cises de torch et transformers ), d'o√π la n√©cessit√© d'un environnement s√©par√©. On l'appelle  melotts_env.

python -m venv melotts_env
source melotts_env/bin/activate # Sur Mac/Linux
# melotts_env\Scripts\activate  # Sur Windows
pip install TTS[ja]





4. T√©l√©charger les mod√®les



Vu que ces mod√®les sont tr√®s lourds, on ne les a pas mis dans le d√©p√¥t.
Il faudra les t√©l√©charger manuellement et les placer dans les bons dossiers. Voici les instructions pr√©cises pour chaque cas.



                       üéôÔ∏è Mod√®les de reconnaissance vocale (Vosk)

Ces mod√®les sont essentiels pour la transcription du fran√ßais et de l'anglais. 
Ils sont l√©gers et tr√®s performants pour l'√©coute en temps r√©el.

Va sur le site officiel de Vosk : https://alphacephei.com/vosk/models

Cherche les mod√®les "French small model" et "English small model".

T√©l√©charge les deux archives .zip correspondantes.

Une fois t√©l√©charg√©es, d√©compresse-les. Cr√©e deux nouveaux dossiers √† la racine de ton projet : vosk-model-fr et vosk-model-en. Place les fichiers extraits dans ces dossiers.

                   üéôÔ∏è Mod√®le de reconnaissance vocale japonais (Whisper)

Rien √† faire ici ! Le mod√®le Whisper d'OpenAI est tr√®s pratique car il se t√©l√©charge automatiquement la premi√®re fois que tu lances un script qui l'utilise. La librairie est d√©j√† incluse dans ton requirements.txt donc l'installation se fait en m√™me temps que le reste des d√©pendances. 

üåê Mod√®le de traduction (SeamlessM4T de Meta)

Ce mod√®le permet de traduire sans connexion Internet. Il est tr√®s volumineux, mais il est au c≈ìur du projet.

Rends-toi sur la page Hugging Face du mod√®le : https://huggingface.co/meta-llama/seamless-m4t-medium

Dans l'onglet "Files and versions", clique sur "Download all files" pour t√©l√©charger le dossier complet. C'est une archive .zip ou tu peux utiliser git lfs si tu es familier avec.

Une fois t√©l√©charg√©, renomme le dossier en hf-seamless-m4t-medium et place-le √† la racine de ton projet.



                    üó£Ô∏è Mod√®les de synth√®se vocale (TTS)
Ici, on a une petite particularit√©. On utilise la librairie melo.api.TTS pour g√©n√©rer la voix. Elle est tr√®s pratique, car elle s'occupe toute seule de t√©l√©charger les mod√®les la premi√®re fois que tu lances un script qui l'utilise.

TTS pour l'anglais, le fran√ßais et le japonais :
Rien √† faire ici ! La librairie melo.api.TTS est con√ßue pour g√©rer le t√©l√©chargement et la mise en cache des mod√®les automatiquement. La premi√®re fois que tu ex√©cuteras un script utilisant un mod√®le pour l'une de ces langues, la librairie v√©rifiera si le mod√®le est pr√©sent. S'il n'est pas dans son dossier de cache par d√©faut, elle le t√©l√©chargera pour toi. C'est la raison pour laquelle il n'y a pas d'√©tapes de t√©l√©chargement manuel pour ces mod√®les dans ce guide.







                       üèÉ Comment lancer l'application

Une fois que tous les mod√®les sont en place, tu peux lancer l'interface utilisateur.

streamlit run app.py

L'application va se lancer automatiquement dans ton navigateur.

‚òÅÔ∏è Pour la mettre en ligne (Kaggle ou Colab)
√áa sera la prochaine √©tape. Quand tu seras pr√™t, il faudra juste uploader tous les fichiers et installer les d√©pendances et les mod√®les directement sur la plateforme.

ü§ù Participer au projet
Si tu as des id√©es pour am√©liorer l'app, n'h√©site pas ! Les pull requests sont les bienvenues.